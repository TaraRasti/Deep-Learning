{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1 class=\"list-group-item list-group-item-success\">Arrhythmia Detection</h1></center>","metadata":{}},{"cell_type":"code","source":"# Importing Required Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv1D\nimport wfdb                            # Package for loading the ecg and annotation\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\nimport warnings\nwarnings.filterwarnings(\"ignore\") \nimport random\nfrom keras.layers import Bidirectional, LSTM\n# Random Initialization\nrandom.seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:27.150812Z","iopub.execute_input":"2023-01-16T15:39:27.151968Z","iopub.status.idle":"2023-01-16T15:39:35.725750Z","shell.execute_reply.started":"2023-01-16T15:39:27.151823Z","shell.execute_reply":"2023-01-16T15:39:35.724280Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing Data\ndata = '../input/mit-bih-arrhythmia-database/'","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:35.730069Z","iopub.execute_input":"2023-01-16T15:39:35.730920Z","iopub.status.idle":"2023-01-16T15:39:35.736593Z","shell.execute_reply.started":"2023-01-16T15:39:35.730858Z","shell.execute_reply":"2023-01-16T15:39:35.735109Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# List of Patients\npatients = ['100','101','102','103','104','105','106','107',\n           '108','109','111','112','113','114','115','116',\n           '117','118','119','121','122','123','124','200',\n           '201','202','203','205','207','208','209','210',\n           '212','213','214','215','217','219','220','221',\n           '222','223','228','230','231','232','233','234']","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:35.739452Z","iopub.execute_input":"2023-01-16T15:39:35.740677Z","iopub.status.idle":"2023-01-16T15:39:35.750570Z","shell.execute_reply.started":"2023-01-16T15:39:35.740616Z","shell.execute_reply":"2023-01-16T15:39:35.749620Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Creating a Empty Dataframe\nsymbols_df = pd.DataFrame()\n\n# Reading all .atr files \nfor pts in patients:\n    # Generating filepath for all .atr file names\n    file = data + pts\n    # Saving annotation object\n    annotation = wfdb.rdann(file, 'atr')\n    # Extracting symbols from the object\n    sym = annotation.symbol\n    # Saving value counts\n    values, counts = np.unique(sym, return_counts=True)\n    # Writing data points into dataframe\n    df_sub = pd.DataFrame({'symbol':values, 'Counts':counts, 'Patient Number':[pts]*len(counts)})\n    # Concatenating all data points  \n    symbols_df = pd.concat([symbols_df, df_sub],axis = 0)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:35.753147Z","iopub.execute_input":"2023-01-16T15:39:35.754362Z","iopub.status.idle":"2023-01-16T15:39:38.096776Z","shell.execute_reply.started":"2023-01-16T15:39:35.754300Z","shell.execute_reply":"2023-01-16T15:39:38.095431Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Value Counts of Different symbols in data\nsymbols_df.groupby('symbol').Counts.sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.101262Z","iopub.execute_input":"2023-01-16T15:39:38.102130Z","iopub.status.idle":"2023-01-16T15:39:38.123191Z","shell.execute_reply.started":"2023-01-16T15:39:38.102057Z","shell.execute_reply":"2023-01-16T15:39:38.120896Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"symbol\nN    75052\nL     8075\nR     7259\nV     7130\n/     7028\nA     2546\n+     1291\nf      982\nF      803\n~      616\n!      472\n\"      437\nj      229\nx      193\na      150\n|      132\nE      106\nJ       83\nQ       33\ne       16\n[        6\n]        6\nS        2\nName: Counts, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Non Beat Symbols\nnonbeat = ['[','!',']','x','(',')','p','t','u','`',\n           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n\n# Abnormal Beat Symbols\nabnormal = ['L','R','V','/','A','f','F','j','a','E','J','e','S']\n\n# Normal Beat Symbols\nnormal = ['N']","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.125324Z","iopub.execute_input":"2023-01-16T15:39:38.126069Z","iopub.status.idle":"2023-01-16T15:39:38.133871Z","shell.execute_reply.started":"2023-01-16T15:39:38.125992Z","shell.execute_reply":"2023-01-16T15:39:38.132403Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Classifying normal, abnormal or nonbeat\nsymbols_df['category'] = -1\nsymbols_df.loc[symbols_df.symbol == 'N','category'] = 0\nsymbols_df.loc[symbols_df.symbol.isin(abnormal), 'category'] = 1","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.136387Z","iopub.execute_input":"2023-01-16T15:39:38.136820Z","iopub.status.idle":"2023-01-16T15:39:38.157172Z","shell.execute_reply.started":"2023-01-16T15:39:38.136768Z","shell.execute_reply":"2023-01-16T15:39:38.155047Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Value counts of different categories\nsymbols_df.groupby('category').Counts.sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.159093Z","iopub.execute_input":"2023-01-16T15:39:38.160673Z","iopub.status.idle":"2023-01-16T15:39:38.173671Z","shell.execute_reply.started":"2023-01-16T15:39:38.160596Z","shell.execute_reply":"2023-01-16T15:39:38.172150Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"category\n-1     3186\n 0    75052\n 1    34409\nName: Counts, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def load_ecg(file):    \n    # load the ecg\n    record = wfdb.rdrecord(file)\n    # load the annotation\n    annotation = wfdb.rdann(file, 'atr')\n    \n    # extracting the signal\n    p_signal = record.p_signal\n\n    # extracting symbols and annotation index\n    atr_sym = annotation.symbol\n    atr_sample = annotation.sample\n    \n    return p_signal, atr_sym, atr_sample","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.175345Z","iopub.execute_input":"2023-01-16T15:39:38.176373Z","iopub.status.idle":"2023-01-16T15:39:38.183835Z","shell.execute_reply.started":"2023-01-16T15:39:38.176316Z","shell.execute_reply":"2023-01-16T15:39:38.182669Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Accessing the load ECG function and getting annotation.symbol, annotation.sample, signals\np_signal, atr_sym, atr_sample = load_ecg(file)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.185947Z","iopub.execute_input":"2023-01-16T15:39:38.186890Z","iopub.status.idle":"2023-01-16T15:39:38.342175Z","shell.execute_reply.started":"2023-01-16T15:39:38.186830Z","shell.execute_reply":"2023-01-16T15:39:38.340802Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def make_dataset(pts, num_sec, fs, abnormal):\n    # function for making dataset ignoring non-beats\n    # input:\n    #   pts - list of patients\n    #   num_sec = number of seconds to include before and after the beat\n    #   fs = frequency\n    # output: \n    #   X_all = signal (nbeats , num_sec * fs columns)\n    #   Y_all = binary is abnormal (nbeats, 1)\n    #   sym_all = beat annotation symbol (nbeats,1)\n    \n    # initialize numpy arrays\n    num_cols = 2*num_sec * fs\n    X_all = np.zeros((1,num_cols))\n    Y_all = np.zeros((1,1))\n    sym_all = []\n    \n    # list to keep track of number of beats across patients\n    max_rows = []\n    \n    for pt in pts:\n        file = data + pt\n        \n        p_signal, atr_sym, atr_sample = load_ecg(file)\n        \n        # grab the first signal\n        p_signal = p_signal[:,0]\n        \n        # make df to exclude the nonbeats\n        df_ann = pd.DataFrame({'atr_sym':atr_sym,\n                              'atr_sample':atr_sample})\n        df_ann = df_ann.loc[df_ann.atr_sym.isin(abnormal + ['N'])]\n        \n        X,Y,sym = build_XY(p_signal,df_ann, num_cols, abnormal)\n        sym_all = sym_all+sym\n        max_rows.append(X.shape[0])\n        X_all = np.append(X_all,X,axis = 0)\n        Y_all = np.append(Y_all,Y,axis = 0)\n        \n    # drop the first zero row\n    X_all = X_all[1:,:]\n    Y_all = Y_all[1:,:]\n\n    return X_all, Y_all, sym_all\n","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.344288Z","iopub.execute_input":"2023-01-16T15:39:38.345097Z","iopub.status.idle":"2023-01-16T15:39:38.359613Z","shell.execute_reply.started":"2023-01-16T15:39:38.345018Z","shell.execute_reply":"2023-01-16T15:39:38.358250Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def build_XY(p_signal, df_ann, num_cols, abnormal):\n    # this function builds the X,Y matrices for each beat\n    # it also returns the original symbols for Y\n    \n    num_rows = len(df_ann)\n\n    X = np.zeros((num_rows, num_cols))\n    Y = np.zeros((num_rows,1))\n    sym = []\n    \n    # keep track of rows\n    max_row = 0\n\n    for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n\n        left = max([0,(atr_sample - num_sec*fs) ])\n        right = min([len(p_signal),(atr_sample + num_sec*fs) ])\n        x = p_signal[left: right]\n        if len(x) == num_cols:\n            X[max_row,:] = x\n            Y[max_row,:] = int(atr_sym in abnormal)\n            sym.append(atr_sym)\n            max_row += 1\n    X = X[:max_row,:]\n    Y = Y[:max_row,:]\n    return X,Y,sym","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.363267Z","iopub.execute_input":"2023-01-16T15:39:38.363679Z","iopub.status.idle":"2023-01-16T15:39:38.378633Z","shell.execute_reply.started":"2023-01-16T15:39:38.363619Z","shell.execute_reply":"2023-01-16T15:39:38.376975Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Parameter Values\nnum_sec = 6\nfs = 360","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.380947Z","iopub.execute_input":"2023-01-16T15:39:38.382238Z","iopub.status.idle":"2023-01-16T15:39:38.389281Z","shell.execute_reply.started":"2023-01-16T15:39:38.382003Z","shell.execute_reply":"2023-01-16T15:39:38.387967Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Accessing the fuction and creating a dataset with ECG digital Points\nX_all, Y_all, sym_all = make_dataset(patients, num_sec, fs, abnormal)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:39:38.395136Z","iopub.execute_input":"2023-01-16T15:39:38.395930Z","iopub.status.idle":"2023-01-16T15:40:22.993272Z","shell.execute_reply.started":"2023-01-16T15:39:38.395874Z","shell.execute_reply":"2023-01-16T15:40:22.990713Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Train Test Split|\nX_train, X_valid, y_train, y_valid = train_test_split(X_all, Y_all, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:23.003563Z","iopub.execute_input":"2023-01-16T15:40:23.007295Z","iopub.status.idle":"2023-01-16T15:40:24.310150Z","shell.execute_reply.started":"2023-01-16T15:40:23.007188Z","shell.execute_reply":"2023-01-16T15:40:24.309091Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout\nfrom keras.layers import Input\nfrom keras.models import Model\nimport os\nimport keras\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import LayerNormalization\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.utils import class_weight\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:24.312110Z","iopub.execute_input":"2023-01-16T15:40:24.312737Z","iopub.status.idle":"2023-01-16T15:40:24.497270Z","shell.execute_reply.started":"2023-01-16T15:40:24.312685Z","shell.execute_reply":"2023-01-16T15:40:24.496079Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPool2D\nfrom keras.layers.core import Dense,Activation,Dropout,Flatten\nfrom keras.utils import np_utils\nfrom keras import *\nimport tensorflow as tf\n\nimport os\nfrom six.moves import cPickle as pickle\nimport platform\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:24.498930Z","iopub.execute_input":"2023-01-16T15:40:24.499451Z","iopub.status.idle":"2023-01-16T15:40:24.507983Z","shell.execute_reply.started":"2023-01-16T15:40:24.499383Z","shell.execute_reply":"2023-01-16T15:40:24.506773Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics\ndef print_report(y_actual, y_pred, thresh):\n    # Function to print evaluation metrics\n    auc = roc_auc_score(y_actual, y_pred)\n    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n    recall = recall_score(y_actual, (y_pred > thresh))\n    precision = precision_score(y_actual, (y_pred > thresh))\n    specificity = sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n    prevalence = (sum(y_actual)/len(y_actual))\n    print('AUC:%.3f'%auc)\n    print('Accuracy:%.3f'%accuracy)\n    print('Recall:%.3f'%recall)\n    print('Precision:%.3f'%precision)\n    print('Specificity:%.3f'%specificity)\n    print('Prevalence:%.3f'%prevalence)\n    print(' ')\n    return auc, accuracy, recall, precision, specificity","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:24.510571Z","iopub.execute_input":"2023-01-16T15:40:24.511450Z","iopub.status.idle":"2023-01-16T15:40:24.524726Z","shell.execute_reply.started":"2023-01-16T15:40:24.511388Z","shell.execute_reply":"2023-01-16T15:40:24.523193Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Threshold Value\nthresh = (sum(y_train)/len(y_train))[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:24.527376Z","iopub.execute_input":"2023-01-16T15:40:24.528204Z","iopub.status.idle":"2023-01-16T15:40:24.596254Z","shell.execute_reply.started":"2023-01-16T15:40:24.528145Z","shell.execute_reply":"2023-01-16T15:40:24.595047Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# reshape input to [samples, time steps, features = 1] for CNN\nX_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_valid_cnn = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n\nprint(X_train_cnn.shape)\nprint(X_valid_cnn.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:24.598365Z","iopub.execute_input":"2023-01-16T15:40:24.598790Z","iopub.status.idle":"2023-01-16T15:40:24.613259Z","shell.execute_reply.started":"2023-01-16T15:40:24.598734Z","shell.execute_reply":"2023-01-16T15:40:24.611794Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(86982, 4320, 1)\n(21746, 4320, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Relu for activation function & Dropout for reducing overfitting by randomly removing some nodes.\nmodel = Sequential()\nmodel.add(Conv1D(filters = 512, kernel_size = 7, activation = 'relu', input_shape = (X_train.shape[1],1)))\nmodel.add(Dropout(rate = 0.5))\nmodel.add(MaxPool1D())\nmodel.add(Flatten())\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n# compile the model with binary crossentropy, and the adam optimizer\nmodel.compile(loss = 'binary_crossentropy',\n                optimizer = 'sgd',\n                metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:24.615683Z","iopub.execute_input":"2023-01-16T15:40:24.616689Z","iopub.status.idle":"2023-01-16T15:40:28.539913Z","shell.execute_reply.started":"2023-01-16T15:40:24.616627Z","shell.execute_reply":"2023-01-16T15:40:28.536392Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"2023-01-16 15:40:24.734422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:24.852256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:24.853603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:24.857496: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-16 15:40:24.859360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:24.860522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:24.861497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:27.859096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:27.860913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:27.862591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-16 15:40:27.863909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:28.541835Z","iopub.execute_input":"2023-01-16T15:40:28.542607Z","iopub.status.idle":"2023-01-16T15:40:28.555395Z","shell.execute_reply.started":"2023-01-16T15:40:28.542551Z","shell.execute_reply":"2023-01-16T15:40:28.553884Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d (Conv1D)              (None, 4314, 512)         4096      \n_________________________________________________________________\ndropout (Dropout)            (None, 4314, 512)         0         \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 2157, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1104384)           0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 1104385   \n=================================================================\nTotal params: 1,108,481\nTrainable params: 1,108,481\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fitting data in model \nmodel.fit(X_train_cnn, y_train, batch_size = 128, epochs= 100, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T15:40:28.557923Z","iopub.execute_input":"2023-01-16T15:40:28.558814Z","iopub.status.idle":"2023-01-16T17:53:24.511905Z","shell.execute_reply.started":"2023-01-16T15:40:28.558750Z","shell.execute_reply":"2023-01-16T17:53:24.510664Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"2023-01-16 15:40:29.299471: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1503048960 exceeds 10% of free system memory.\n2023-01-16 15:40:31.281418: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1503048960 exceeds 10% of free system memory.\n2023-01-16 15:40:32.752209: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2023-01-16 15:40:34.504587: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"680/680 [==============================] - 88s 118ms/step - loss: 0.3598 - accuracy: 0.8538\nEpoch 2/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.2518 - accuracy: 0.9095\nEpoch 3/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.2223 - accuracy: 0.9235\nEpoch 4/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.2075 - accuracy: 0.9299\nEpoch 5/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1991 - accuracy: 0.9334\nEpoch 6/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1907 - accuracy: 0.9367\nEpoch 7/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1850 - accuracy: 0.9390\nEpoch 8/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1791 - accuracy: 0.9416\nEpoch 9/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1754 - accuracy: 0.9434\nEpoch 10/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1713 - accuracy: 0.9444\nEpoch 11/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1681 - accuracy: 0.9456\nEpoch 12/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1652 - accuracy: 0.9469\nEpoch 13/100\n680/680 [==============================] - 79s 117ms/step - loss: 0.1621 - accuracy: 0.9480\nEpoch 14/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1578 - accuracy: 0.9492\nEpoch 15/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1550 - accuracy: 0.9504\nEpoch 16/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1526 - accuracy: 0.9510\nEpoch 17/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1486 - accuracy: 0.9522\nEpoch 18/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1471 - accuracy: 0.9527\nEpoch 19/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1430 - accuracy: 0.9547\nEpoch 20/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1412 - accuracy: 0.9547\nEpoch 21/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1373 - accuracy: 0.9564\nEpoch 22/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1360 - accuracy: 0.9563\nEpoch 23/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1328 - accuracy: 0.9582\nEpoch 24/100\n680/680 [==============================] - 79s 116ms/step - loss: 0.1305 - accuracy: 0.9591\nEpoch 25/100\n680/680 [==============================] - 79s 116ms/step - loss: 0.1276 - accuracy: 0.9601\nEpoch 26/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1255 - accuracy: 0.9603\nEpoch 27/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1230 - accuracy: 0.9609\nEpoch 28/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1211 - accuracy: 0.9614\nEpoch 29/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1192 - accuracy: 0.9623\nEpoch 30/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1172 - accuracy: 0.9632\nEpoch 31/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1151 - accuracy: 0.9640\nEpoch 32/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1132 - accuracy: 0.9650\nEpoch 33/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1107 - accuracy: 0.9651\nEpoch 34/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1098 - accuracy: 0.9656\nEpoch 35/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1076 - accuracy: 0.9661\nEpoch 36/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1070 - accuracy: 0.9666\nEpoch 37/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1049 - accuracy: 0.9671\nEpoch 38/100\n680/680 [==============================] - 79s 117ms/step - loss: 0.1031 - accuracy: 0.9677\nEpoch 39/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.1015 - accuracy: 0.9688\nEpoch 40/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0998 - accuracy: 0.9686\nEpoch 41/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0987 - accuracy: 0.9692\nEpoch 42/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0970 - accuracy: 0.9694\nEpoch 43/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0956 - accuracy: 0.9698\nEpoch 44/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0951 - accuracy: 0.9704\nEpoch 45/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0932 - accuracy: 0.9710\nEpoch 46/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0923 - accuracy: 0.9708\nEpoch 47/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0911 - accuracy: 0.9716\nEpoch 48/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0902 - accuracy: 0.9718\nEpoch 49/100\n680/680 [==============================] - 79s 117ms/step - loss: 0.0889 - accuracy: 0.9719\nEpoch 50/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0890 - accuracy: 0.9723\nEpoch 51/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0872 - accuracy: 0.9724\nEpoch 52/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0866 - accuracy: 0.9724\nEpoch 53/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0852 - accuracy: 0.9733\nEpoch 54/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0839 - accuracy: 0.9734\nEpoch 55/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0834 - accuracy: 0.9740\nEpoch 56/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0828 - accuracy: 0.9740\nEpoch 57/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0816 - accuracy: 0.9744\nEpoch 58/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0810 - accuracy: 0.9745\nEpoch 59/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0801 - accuracy: 0.9746\nEpoch 60/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0792 - accuracy: 0.9748\nEpoch 61/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0782 - accuracy: 0.9753\nEpoch 62/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0775 - accuracy: 0.9758\nEpoch 63/100\n680/680 [==============================] - 79s 117ms/step - loss: 0.0773 - accuracy: 0.9754\nEpoch 64/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0765 - accuracy: 0.9756\nEpoch 65/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0760 - accuracy: 0.9762\nEpoch 66/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0748 - accuracy: 0.9763\nEpoch 67/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0751 - accuracy: 0.9765\nEpoch 68/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0745 - accuracy: 0.9765\nEpoch 69/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0732 - accuracy: 0.9770\nEpoch 70/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0725 - accuracy: 0.9773\nEpoch 71/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0726 - accuracy: 0.9770\nEpoch 72/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0719 - accuracy: 0.9768\nEpoch 73/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0710 - accuracy: 0.9777\nEpoch 74/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0708 - accuracy: 0.9775\nEpoch 75/100\n680/680 [==============================] - 79s 117ms/step - loss: 0.0698 - accuracy: 0.9779\nEpoch 76/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0696 - accuracy: 0.9782\nEpoch 77/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0683 - accuracy: 0.9783\nEpoch 78/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0679 - accuracy: 0.9788\nEpoch 79/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0681 - accuracy: 0.9784\nEpoch 80/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0671 - accuracy: 0.9788\nEpoch 81/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0672 - accuracy: 0.9787\nEpoch 82/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0664 - accuracy: 0.9793\nEpoch 83/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0660 - accuracy: 0.9789\nEpoch 84/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0650 - accuracy: 0.9799\nEpoch 85/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0645 - accuracy: 0.9795\nEpoch 86/100\n680/680 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.97 - 80s 117ms/step - loss: 0.0645 - accuracy: 0.9796\nEpoch 87/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0639 - accuracy: 0.9800\nEpoch 88/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0633 - accuracy: 0.9797\nEpoch 89/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0635 - accuracy: 0.9801\nEpoch 90/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0632 - accuracy: 0.9801\nEpoch 91/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0627 - accuracy: 0.9802\nEpoch 92/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0619 - accuracy: 0.9805\nEpoch 93/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0618 - accuracy: 0.9806\nEpoch 94/100\n680/680 [==============================] - 79s 117ms/step - loss: 0.0615 - accuracy: 0.9804\nEpoch 95/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0613 - accuracy: 0.9805\nEpoch 96/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0606 - accuracy: 0.9810\nEpoch 97/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0602 - accuracy: 0.9806\nEpoch 98/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0596 - accuracy: 0.9812\nEpoch 99/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0595 - accuracy: 0.9812\nEpoch 100/100\n680/680 [==============================] - 80s 117ms/step - loss: 0.0587 - accuracy: 0.9817\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fac44033490>"},"metadata":{}}]},{"cell_type":"code","source":"# Predictions\ny_train_preds_cnn = model.predict(X_train_cnn,verbose = 1)\ny_valid_preds_cnn = model.predict(X_valid_cnn,verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T17:53:24.514307Z","iopub.execute_input":"2023-01-16T17:53:24.514732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics\nprint('Train');\nprint_report(y_train, y_train_preds_cnn, thresh)\nprint('Valid');\nprint_report(y_valid, y_valid_preds_cnn, thresh);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\n\nfpr_valid_cnn, tpr_valid_cnn, t_valid_cnn = roc_curve(y_valid, y_valid_preds_cnn)\nauc_valid_cnn = roc_auc_score(y_valid, y_valid_preds_cnn)\n\n\n\n\nplt.plot(fpr_valid_cnn, tpr_valid_cnn, 'g-', label = 'CNN AUC:%.3f'%auc_valid_cnn)\n\n\n\nplt.plot([0,1],[0,1], 'k--')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\nplt.title('Validation Set')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}