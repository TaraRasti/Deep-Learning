{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1 class=\"list-group-item list-group-item-success\">Arrhythmia Detection</h1></center>","metadata":{}},{"cell_type":"code","source":"# Importing Required Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv1D\nimport wfdb                            # Package for loading the ecg and annotation\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\nimport warnings\nwarnings.filterwarnings(\"ignore\") \nimport random\nfrom keras.layers import Bidirectional, LSTM\n# Random Initialization\nrandom.seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:44.764548Z","iopub.execute_input":"2023-01-31T15:38:44.764946Z","iopub.status.idle":"2023-01-31T15:38:50.126856Z","shell.execute_reply.started":"2023-01-31T15:38:44.764847Z","shell.execute_reply":"2023-01-31T15:38:50.126039Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing Data\ndata = '../input/mit-bih-arrhythmia-database/'","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:50.130076Z","iopub.execute_input":"2023-01-31T15:38:50.130303Z","iopub.status.idle":"2023-01-31T15:38:50.134195Z","shell.execute_reply.started":"2023-01-31T15:38:50.130269Z","shell.execute_reply":"2023-01-31T15:38:50.133350Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# List of Patients\npatients = ['100','101','102','103','104','105','106','107',\n           '108','109','111','112','113','114','115','116',\n           '117','118','119','121','122','123','124','200',\n           '201','202','203','205','207','208','209','210',\n           '212','213','214','215','217','219','220','221',\n           '222','223','228','230','231','232','233','234']","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:50.136192Z","iopub.execute_input":"2023-01-31T15:38:50.136867Z","iopub.status.idle":"2023-01-31T15:38:50.147056Z","shell.execute_reply.started":"2023-01-31T15:38:50.136827Z","shell.execute_reply":"2023-01-31T15:38:50.146181Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Creating a Empty Dataframe\nsymbols_df = pd.DataFrame()\n\n# Reading all .atr files \nfor pts in patients:\n    # Generating filepath for all .atr file names\n    file = data + pts\n    # Saving annotation object\n    annotation = wfdb.rdann(file, 'atr')\n    # Extracting symbols from the object\n    sym = annotation.symbol\n    # Saving value counts\n    values, counts = np.unique(sym, return_counts=True)\n    # Writing data points into dataframe\n    df_sub = pd.DataFrame({'symbol':values, 'Counts':counts, 'Patient Number':[pts]*len(counts)})\n    # Concatenating all data points  \n    symbols_df = pd.concat([symbols_df, df_sub],axis = 0)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:50.148501Z","iopub.execute_input":"2023-01-31T15:38:50.148779Z","iopub.status.idle":"2023-01-31T15:38:52.003220Z","shell.execute_reply.started":"2023-01-31T15:38:50.148745Z","shell.execute_reply":"2023-01-31T15:38:52.002331Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Value Counts of Different symbols in data\nsymbols_df.groupby('symbol').Counts.sum().sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.005640Z","iopub.execute_input":"2023-01-31T15:38:52.005919Z","iopub.status.idle":"2023-01-31T15:38:52.019410Z","shell.execute_reply.started":"2023-01-31T15:38:52.005883Z","shell.execute_reply":"2023-01-31T15:38:52.018621Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"symbol\nN    75052\nL     8075\nR     7259\nV     7130\n/     7028\nA     2546\n+     1291\nf      982\nF      803\n~      616\n!      472\n\"      437\nj      229\nx      193\na      150\n|      132\nE      106\nJ       83\nQ       33\ne       16\n[        6\n]        6\nS        2\nName: Counts, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Non Beat Symbols\nnonbeat = ['[','!',']','x','(',')','p','t','u','`',\n           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n\n# Abnormal Beat Symbols\nabnormal = ['L','R','V','/','A','f','F','j','a','E','J','e','S']\n\n# Normal Beat Symbols\nnormal = ['N']","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.020934Z","iopub.execute_input":"2023-01-31T15:38:52.021983Z","iopub.status.idle":"2023-01-31T15:38:52.030513Z","shell.execute_reply.started":"2023-01-31T15:38:52.021943Z","shell.execute_reply":"2023-01-31T15:38:52.029555Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Classifying normal, abnormal or nonbeat\nsymbols_df['category'] = -1\nsymbols_df.loc[symbols_df.symbol == 'N','category'] = 0\nsymbols_df.loc[symbols_df.symbol.isin(abnormal), 'category'] = 1","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.031774Z","iopub.execute_input":"2023-01-31T15:38:52.032097Z","iopub.status.idle":"2023-01-31T15:38:52.042750Z","shell.execute_reply.started":"2023-01-31T15:38:52.032060Z","shell.execute_reply":"2023-01-31T15:38:52.041912Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Value counts of different categories\nsymbols_df.groupby('category').Counts.sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.043894Z","iopub.execute_input":"2023-01-31T15:38:52.044889Z","iopub.status.idle":"2023-01-31T15:38:52.055917Z","shell.execute_reply.started":"2023-01-31T15:38:52.044845Z","shell.execute_reply":"2023-01-31T15:38:52.055126Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"category\n-1     3186\n 0    75052\n 1    34409\nName: Counts, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def load_ecg(file):    \n    # load the ecg\n    record = wfdb.rdrecord(file)\n    # load the annotation\n    annotation = wfdb.rdann(file, 'atr')\n    \n    # extracting the signal\n    p_signal = record.p_signal\n\n    # extracting symbols and annotation index\n    atr_sym = annotation.symbol\n    atr_sample = annotation.sample\n    \n    return p_signal, atr_sym, atr_sample","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.057482Z","iopub.execute_input":"2023-01-31T15:38:52.058188Z","iopub.status.idle":"2023-01-31T15:38:52.066319Z","shell.execute_reply.started":"2023-01-31T15:38:52.058150Z","shell.execute_reply":"2023-01-31T15:38:52.065553Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Accessing the load ECG function and getting annotation.symbol, annotation.sample, signals\np_signal, atr_sym, atr_sample = load_ecg(file)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.067484Z","iopub.execute_input":"2023-01-31T15:38:52.068019Z","iopub.status.idle":"2023-01-31T15:38:52.185384Z","shell.execute_reply.started":"2023-01-31T15:38:52.067983Z","shell.execute_reply":"2023-01-31T15:38:52.184588Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def make_dataset(pts, num_sec, fs, abnormal):\n    # function for making dataset ignoring non-beats\n    # input:\n    #   pts - list of patients\n    #   num_sec = number of seconds to include before and after the beat\n    #   fs = frequency\n    # output: \n    #   X_all = signal (nbeats , num_sec * fs columns)\n    #   Y_all = binary is abnormal (nbeats, 1)\n    #   sym_all = beat annotation symbol (nbeats,1)\n    \n    # initialize numpy arrays\n    num_cols = 2*num_sec * fs\n    X_all = np.zeros((1,num_cols))\n    Y_all = np.zeros((1,1))\n    sym_all = []\n    \n    # list to keep track of number of beats across patients\n    max_rows = []\n    \n    for pt in pts:\n        file = data + pt\n        \n        p_signal, atr_sym, atr_sample = load_ecg(file)\n        \n        # grab the first signal\n        p_signal = p_signal[:,0]\n        \n        # make df to exclude the nonbeats\n        df_ann = pd.DataFrame({'atr_sym':atr_sym,\n                              'atr_sample':atr_sample})\n        df_ann = df_ann.loc[df_ann.atr_sym.isin(abnormal + ['N'])]\n        \n        X,Y,sym = build_XY(p_signal,df_ann, num_cols, abnormal)\n        sym_all = sym_all+sym\n        max_rows.append(X.shape[0])\n        X_all = np.append(X_all,X,axis = 0)\n        Y_all = np.append(Y_all,Y,axis = 0)\n        \n    # drop the first zero row\n    X_all = X_all[1:,:]\n    Y_all = Y_all[1:,:]\n\n    return X_all, Y_all, sym_all\n","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.186972Z","iopub.execute_input":"2023-01-31T15:38:52.187231Z","iopub.status.idle":"2023-01-31T15:38:52.196167Z","shell.execute_reply.started":"2023-01-31T15:38:52.187196Z","shell.execute_reply":"2023-01-31T15:38:52.194949Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def build_XY(p_signal, df_ann, num_cols, abnormal):\n    # this function builds the X,Y matrices for each beat\n    # it also returns the original symbols for Y\n    \n    num_rows = len(df_ann)\n\n    X = np.zeros((num_rows, num_cols))\n    Y = np.zeros((num_rows,1))\n    sym = []\n    \n    # keep track of rows\n    max_row = 0\n\n    for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n\n        left = max([0,(atr_sample - num_sec*fs) ])\n        right = min([len(p_signal),(atr_sample + num_sec*fs) ])\n        x = p_signal[left: right]\n        if len(x) == num_cols:\n            X[max_row,:] = x\n            Y[max_row,:] = int(atr_sym in abnormal)\n            sym.append(atr_sym)\n            max_row += 1\n    X = X[:max_row,:]\n    Y = Y[:max_row,:]\n    return X,Y,sym","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.197355Z","iopub.execute_input":"2023-01-31T15:38:52.197902Z","iopub.status.idle":"2023-01-31T15:38:52.209420Z","shell.execute_reply.started":"2023-01-31T15:38:52.197864Z","shell.execute_reply":"2023-01-31T15:38:52.208687Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Parameter Values\nnum_sec = 6\nfs = 360","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.210996Z","iopub.execute_input":"2023-01-31T15:38:52.211299Z","iopub.status.idle":"2023-01-31T15:38:52.220664Z","shell.execute_reply.started":"2023-01-31T15:38:52.211221Z","shell.execute_reply":"2023-01-31T15:38:52.219979Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Accessing the fuction and creating a dataset with ECG digital Points\nX_all, Y_all, sym_all = make_dataset(patients, num_sec, fs, abnormal)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:38:52.224449Z","iopub.execute_input":"2023-01-31T15:38:52.224708Z","iopub.status.idle":"2023-01-31T15:39:31.612735Z","shell.execute_reply.started":"2023-01-31T15:38:52.224663Z","shell.execute_reply":"2023-01-31T15:39:31.611919Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Train Test Split|\nX_train, X_valid, y_train, y_valid = train_test_split(X_all, Y_all, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:31.614317Z","iopub.execute_input":"2023-01-31T15:39:31.614574Z","iopub.status.idle":"2023-01-31T15:39:32.684057Z","shell.execute_reply.started":"2023-01-31T15:39:31.614538Z","shell.execute_reply":"2023-01-31T15:39:32.683219Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout\nfrom keras.layers import Input\nfrom keras.models import Model\nimport os\nimport keras\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import LayerNormalization\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.utils import class_weight\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:32.685610Z","iopub.execute_input":"2023-01-31T15:39:32.685910Z","iopub.status.idle":"2023-01-31T15:39:32.800111Z","shell.execute_reply.started":"2023-01-31T15:39:32.685869Z","shell.execute_reply":"2023-01-31T15:39:32.799320Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPool2D\nfrom keras.layers.core import Dense,Activation,Dropout,Flatten\nfrom keras.utils import np_utils\nfrom keras import *\nimport tensorflow as tf\n\nimport os\nfrom six.moves import cPickle as pickle\nimport platform\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:32.801553Z","iopub.execute_input":"2023-01-31T15:39:32.801854Z","iopub.status.idle":"2023-01-31T15:39:32.807310Z","shell.execute_reply.started":"2023-01-31T15:39:32.801814Z","shell.execute_reply":"2023-01-31T15:39:32.806584Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Evaluation Metrics\ndef print_report(y_actual, y_pred, thresh):\n    # Function to print evaluation metrics\n    auc = roc_auc_score(y_actual, y_pred)\n    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n    recall = recall_score(y_actual, (y_pred > thresh))\n    precision = precision_score(y_actual, (y_pred > thresh))\n    specificity = sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n    prevalence = (sum(y_actual)/len(y_actual))\n    print('AUC:%.3f'%auc)\n    print('Accuracy:%.3f'%accuracy)\n    print('Recall:%.3f'%recall)\n    print('Precision:%.3f'%precision)\n    print('Specificity:%.3f'%specificity)\n    print('Prevalence:%.3f'%prevalence)\n    print(' ')\n    return auc, accuracy, recall, precision, specificity","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:32.808501Z","iopub.execute_input":"2023-01-31T15:39:32.809421Z","iopub.status.idle":"2023-01-31T15:39:32.821196Z","shell.execute_reply.started":"2023-01-31T15:39:32.809382Z","shell.execute_reply":"2023-01-31T15:39:32.820158Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Threshold Value\nthresh = (sum(y_train)/len(y_train))[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:32.822284Z","iopub.execute_input":"2023-01-31T15:39:32.823198Z","iopub.status.idle":"2023-01-31T15:39:32.876240Z","shell.execute_reply.started":"2023-01-31T15:39:32.823161Z","shell.execute_reply":"2023-01-31T15:39:32.875399Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# reshape input to [samples, time steps, features = 1] for CNN\nX_train_cnn = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_valid_cnn = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n\nprint(X_train_cnn.shape)\nprint(X_valid_cnn.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:32.877217Z","iopub.execute_input":"2023-01-31T15:39:32.877409Z","iopub.status.idle":"2023-01-31T15:39:32.888550Z","shell.execute_reply.started":"2023-01-31T15:39:32.877386Z","shell.execute_reply":"2023-01-31T15:39:32.887637Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(86982, 4320, 1)\n(21746, 4320, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Relu for activation function & Dropout for reducing overfitting by randomly removing some nodes.\nmodel = Sequential()\nmodel.add(Conv1D(filters = 512, kernel_size = 15, activation = 'relu', input_shape = (X_train.shape[1],1)))\nmodel.add(Dropout(rate = 0.5))\nmodel.add(MaxPool1D())\nmodel.add(Flatten())\nmodel.add(Dense(1, activation = 'sigmoid'))\n\n# compile the model with binary crossentropy, and the adam optimizer\nmodel.compile(loss = 'binary_crossentropy',\n                optimizer = 'sgd',\n                metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:32.889630Z","iopub.execute_input":"2023-01-31T15:39:32.889901Z","iopub.status.idle":"2023-01-31T15:39:35.600518Z","shell.execute_reply.started":"2023-01-31T15:39:32.889875Z","shell.execute_reply":"2023-01-31T15:39:35.599770Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"2023-01-31 15:39:32.986905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:33.077270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:33.078051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:33.079530: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-31 15:39:33.080733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:33.081465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:33.082178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:35.178278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:35.179146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:35.179825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-31 15:39:35.180448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:35.601712Z","iopub.execute_input":"2023-01-31T15:39:35.601975Z","iopub.status.idle":"2023-01-31T15:39:35.613517Z","shell.execute_reply.started":"2023-01-31T15:39:35.601942Z","shell.execute_reply":"2023-01-31T15:39:35.612159Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d (Conv1D)              (None, 4306, 512)         8192      \n_________________________________________________________________\ndropout (Dropout)            (None, 4306, 512)         0         \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 2153, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1102336)           0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 1102337   \n=================================================================\nTotal params: 1,110,529\nTrainable params: 1,110,529\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fitting data in model \nmodel.fit(X_train_cnn, y_train, batch_size = 128, epochs= 40, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:39:35.615219Z","iopub.execute_input":"2023-01-31T15:39:35.615517Z","iopub.status.idle":"2023-01-31T16:32:01.523242Z","shell.execute_reply.started":"2023-01-31T15:39:35.615482Z","shell.execute_reply":"2023-01-31T16:32:01.522497Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"2023-01-31 15:39:36.193387: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1503048960 exceeds 10% of free system memory.\n2023-01-31 15:39:37.913598: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1503048960 exceeds 10% of free system memory.\n2023-01-31 15:39:39.165664: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n","output_type":"stream"},{"name":"stderr","text":"2023-01-31 15:39:40.400867: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"680/680 [==============================] - 85s 115ms/step - loss: 0.3567 - accuracy: 0.8543\nEpoch 2/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.2421 - accuracy: 0.9134\nEpoch 3/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.2101 - accuracy: 0.9275\nEpoch 4/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1901 - accuracy: 0.9357\nEpoch 5/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1763 - accuracy: 0.9411\nEpoch 6/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1644 - accuracy: 0.9466\nEpoch 7/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1532 - accuracy: 0.9501\nEpoch 8/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1451 - accuracy: 0.9524\nEpoch 9/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1376 - accuracy: 0.9558\nEpoch 10/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1308 - accuracy: 0.9575\nEpoch 11/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1258 - accuracy: 0.9596\nEpoch 12/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1204 - accuracy: 0.9611\nEpoch 13/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1154 - accuracy: 0.9635\nEpoch 14/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1113 - accuracy: 0.9647\nEpoch 15/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1075 - accuracy: 0.9664\nEpoch 16/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1038 - accuracy: 0.9674\nEpoch 17/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.1010 - accuracy: 0.9680\nEpoch 18/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0982 - accuracy: 0.9695\nEpoch 19/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0954 - accuracy: 0.9704\nEpoch 20/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0928 - accuracy: 0.9712\nEpoch 21/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0902 - accuracy: 0.9721\nEpoch 22/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0886 - accuracy: 0.9726\nEpoch 23/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0863 - accuracy: 0.9732\nEpoch 24/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0848 - accuracy: 0.9736\nEpoch 25/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0835 - accuracy: 0.9741\nEpoch 26/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0817 - accuracy: 0.9746\nEpoch 27/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0800 - accuracy: 0.9754\nEpoch 28/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0787 - accuracy: 0.9750\nEpoch 29/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0769 - accuracy: 0.9761\nEpoch 30/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0760 - accuracy: 0.9764\nEpoch 31/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0754 - accuracy: 0.9765\nEpoch 32/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0738 - accuracy: 0.9767\nEpoch 33/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0727 - accuracy: 0.9774\nEpoch 34/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0715 - accuracy: 0.9777\nEpoch 35/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0702 - accuracy: 0.9779\nEpoch 36/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0694 - accuracy: 0.9782\nEpoch 37/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0690 - accuracy: 0.9785\nEpoch 38/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0679 - accuracy: 0.9788\nEpoch 39/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0669 - accuracy: 0.9792\nEpoch 40/40\n680/680 [==============================] - 78s 115ms/step - loss: 0.0666 - accuracy: 0.9790\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f898ed07990>"},"metadata":{}}]},{"cell_type":"code","source":"# Predictions\ny_train_preds_cnn = model.predict(X_train_cnn,verbose = 1)\ny_valid_preds_cnn = model.predict(X_valid_cnn,verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T16:32:01.524521Z","iopub.execute_input":"2023-01-31T16:32:01.524835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics\nprint('Train');\nprint_report(y_train, y_train_preds_cnn, thresh)\nprint('Valid');\nprint_report(y_valid, y_valid_preds_cnn, thresh);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\n\nfpr_valid_cnn, tpr_valid_cnn, t_valid_cnn = roc_curve(y_valid, y_valid_preds_cnn)\nauc_valid_cnn = roc_auc_score(y_valid, y_valid_preds_cnn)\n\n\n\n\nplt.plot(fpr_valid_cnn, tpr_valid_cnn, 'g-', label = 'CNN AUC:%.3f'%auc_valid_cnn)\n\n\n\nplt.plot([0,1],[0,1], 'k--')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\nplt.title('Validation Set')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}